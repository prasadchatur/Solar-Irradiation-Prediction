{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These datasets are meteorological data from the HI-SEAS weather station from four months (September through December 2016) between Mission IV and Mission V.\n",
    "\n",
    "For each dataset, the fields are:\n",
    "\n",
    "A row number (1-n) useful in sorting this export's results\n",
    "The UNIX time_t date (seconds since Jan 1, 1970). Useful in sorting this export's results with other export's results\n",
    "The date in yyyy-mm-dd format\n",
    "The local time of day in hh:mm:ss 24-hour format\n",
    "The numeric data, if any (may be an empty string)\n",
    "The text data, if any (may be an empty string)\n",
    "\n",
    "The units of each dataset are:\n",
    "\n",
    "- Solar radiation: watts per meter^2\n",
    "- Temperature: degrees Fahrenheit\n",
    "- Humidity: percent\n",
    "- Barometric pressure: Hg\n",
    "- Wind direction: degrees\n",
    "- Wind speed: miles per hour\n",
    "- Sunrise/sunset: Hawaii time\n",
    "\n",
    "Link: https://www.kaggle.com/datasets/dronio/SolarEnergy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Importing Libraries\n",
    "2. Loading Data\n",
    "3. Data Wrangling\n",
    "4. Feature Selection using Correlation Matrix\n",
    "5. Feature Selection using SelectKBest Method\n",
    "6. Feature Selection using Extra Tree Classifier\n",
    "7. Feature Engineering with BoxCox, Log, Min-Max and Standard transformation\n",
    "8. Preparing data - Standardisation and Splitting\n",
    "9. Prediction with XGBoost\n",
    "10. Using MultiLayer Perceptron for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# !pip install xgboost\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout, Activation\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SGD, Adam\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# !pip install xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"solar_irradiance data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the date from the date_time format of the 'Data' parameter\n",
    "df['Data'] = df['Data'].apply(lambda x : x.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the date time features from the given parameter using date time python methods\n",
    "df['Month'] = pd.to_datetime(df['Data']).dt.month\n",
    "df['Day'] = pd.to_datetime(df['Data']).dt.day\n",
    "df['Hour'] = pd.to_datetime(df['Time']).dt.hour\n",
    "df['Minute'] = pd.to_datetime(df['Time']).dt.minute\n",
    "df['Second'] = pd.to_datetime(df['Time']).dt.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the sunrise and sunset information using regular expression\n",
    "df['risehour'] = df['TimeSunRise'].apply(lambda x : re.search(r'^\\d+', x).group(0)).astype(int)\n",
    "df['riseminuter'] = df['TimeSunRise'].apply(lambda x : re.search(r'(?<=\\:)\\d+(?=\\:)', x).group(0)).astype(int)\n",
    "\n",
    "df['sethour'] = df['TimeSunSet'].apply(lambda x : re.search(r'^\\d+', x).group(0)).astype(int)\n",
    "df['setminute'] = df['TimeSunSet'].apply(lambda x : re.search(r'(?<=\\:)\\d+(?=\\:)', x).group(0)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the parameters that are not required after extracting the relevant information\n",
    "df.drop(['UNIXTime', 'Data', 'Time', 'TimeSunRise', 'TimeSunSet'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check of data dimensions\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for null values in the data\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glimpse of the final data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(df['Radiation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = df.drop('Radiation', axis = 1)\n",
    "target = df['Radiation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection using Correlation Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "r=\\frac{\\sum\\left(x_i-\\bar{x}\\right)\\left(y_i-\\bar{y}\\right)}{\\sqrt{\\sum\\left(x_i-\\bar{x}\\right)^2 \\sum\\left(y_i-\\bar{y}\\right)^2}}\n",
    "$$\n",
    "- $r=$ correlation coefficient\n",
    "- $x_i=$ values of the $\\mathrm{x}$-variable in a sample\n",
    "- $\\bar{x}=$ mean of the values of the $\\mathrm{x}$-variable\n",
    "- $y_i=$ values of the $y$-variable in a sample\n",
    "- $\\bar{y}=$ mean of the values of the $y$-variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the correlation between the data features\n",
    "corr_matrix = df.corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the correlation matrix using heatmap for clear understanding\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(df.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection using SelectKBest Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GFG article link to $chi^{2}$ test - https://www.geeksforgeeks.org/chi-square-test-for-feature-selection-mathematical-explanation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestfeatures = SelectKBest(score_func = chi2, k = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works on the target label but instead we are passsing continuous float values to it. So, we need to convert our data to label form and there are two methods as follows:\n",
    "- usign LabelEncoder\n",
    "- multiplying the data by 100 and converting it to int which can be treated as labels by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the label encoder\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "train_Y = label_encoder.fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cont = df['Radiation'].apply(lambda x : int(x*100))\n",
    "scaled_input_features = MinMaxScaler().fit_transform(input_features)\n",
    "fit = bestfeatures.fit(scaled_input_features, target_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(fit.scores_)\n",
    "column = pd.DataFrame(input_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contatinating data_features with the scores\n",
    "featureScores = pd.concat([column, scores], axis=1)\n",
    "\n",
    "#naming the dataframe columns\n",
    "featureScores.columns = ['Features', 'feature_imp'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best features\n",
    "featureScores.sort_values(by = 'feature_imp', ascending=False, inplace=True)\n",
    "featureScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise the feature importance\n",
    "plt.figure(figsize = (10, 6))\n",
    "plt.bar(featureScores.Features, featureScores.feature_imp)\n",
    "plt.xticks(rotation = 70)\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.title(\"Feature Importance using Extra Tree Classifier\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection using Extra Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExtraTreesClassifier(verbose = 2, n_estimators = 10)\n",
    "model.fit(scaled_input_features, target_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(model.feature_importances_, index = input_features.columns, columns = [\"feature_imp\"])\n",
    "feature_importances.sort_values(by = 'feature_imp', ascending=False, inplace = True)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 6))\n",
    "plt.bar(feature_importances.index, feature_importances[\"feature_imp\"])\n",
    "plt.xticks(rotation = 70)\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.title(\"Feature Importance using Extra Tree Classifier\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering with BoxCox, Log, Min-Max and Standard transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking for transformation\n",
    "features_to_transform = ['Temperature', 'Pressure', 'Humidity', 'Speed', 'WindDirection(Degrees)']\n",
    "\n",
    "for i in features_to_transform:\n",
    "    \n",
    "    fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(5, 1, figsize=(10, 5))\n",
    "    \n",
    "    pd.DataFrame(input_features[i]).hist(ax = ax1, bins = 50)\n",
    "    pd.DataFrame((input_features[i]+1).transform(np.log)).hist(ax = ax2, bins = 50)\n",
    "    pd.DataFrame(stats.boxcox(input_features[i]+1)[0]).hist(ax = ax3, bins = 50)    \n",
    "    pd.DataFrame(StandardScaler().fit_transform(np.array(input_features[i]).reshape(-1, 1))).hist(ax = ax4, bins = 50)\n",
    "    pd.DataFrame(MinMaxScaler().fit_transform(np.array(input_features[i]).reshape(-1, 1))).hist(ax = ax5, bins = 50)\n",
    "    \n",
    "    ax1.set_ylabel('Normal')\n",
    "    ax2.set_ylabel('Log')\n",
    "    ax3.set_ylabel('Box Cox')\n",
    "    ax4.set_ylabel('Standard')\n",
    "    ax5.set_ylabel('MinMax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the transformations required\n",
    "transform = {'Temperature' : (input_features['Temperature']+1).transform(np.log), \n",
    "             'Pressure': stats.boxcox(input_features['Pressure']+1)[0], \n",
    "            'Humidity' : stats.boxcox(input_features['Humidity']+1)[0], \n",
    "            'Speed' : (input_features['Speed']+1).transform(np.log), \n",
    "            'WindDirection(Degrees)' : MinMaxScaler().fit_transform(\n",
    "                np.array(input_features['WindDirection(Degrees)']).reshape(-1, 1))}\n",
    "\n",
    "for i in transform:\n",
    "    input_features[i] = transform[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data - Standardisation and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(input_features, target, test_size=0.2, random_state=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "xtrain = scaler.fit_transform(xtrain)\n",
    "xtest = scaler.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.shape, xtest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare parameters\n",
    "params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 8}\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "model = XGBRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "model.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('XGBoost model result: {0:0.4f}'. format(np.sqrt(mean_squared_error(ytest, y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(ytest, y_pred))\n",
    "r2 = r2_score(ytest, y_pred)\n",
    "\n",
    "print(\"Testing performance\")XG\n",
    "\n",
    "print(\"RMSE: {:.2f}\".format(rmse))\n",
    "print(\"R2: {:.2f}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using MultiLayer Perceptron for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(input_features, target, test_size=0.2, random_state=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "xtrain = scaler.fit_transform(xtrain)\n",
    "xtest = scaler.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "model = Sequential()\n",
    "    \n",
    "model.add(Dense(128, activation='relu', input_dim=14))\n",
    "model.add(Dropout(0.33))\n",
    "    \n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.33))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.33))\n",
    "\n",
    "model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "model.compile(metrics='mse', loss='mae', optimizer=Adam(learning_rate=0.001))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(xtrain, ytrain, validation_split=0.1, epochs=50, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = history.history\n",
    "for i in fit:\n",
    "    plt.plot(fit[i])\n",
    "    plt.title(i + ' over epochs')\n",
    "    plt.ylabel(i)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(xtest, ytest)\n",
    "mae = scores[0]\n",
    "mse = scores[1]\n",
    "print('Mean absolute error: ', mae)\n",
    "r2 = r2_score(ytest, y_pred)\n",
    "print(\"R2: {:.2f}\".format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(ytest, model.predict(xtest))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
